\chapter{Stating the modularity lifting theorems}

I think that a nice and accessible goal (which will maybe take a month or two) would be to \emph{state} the modularity lifting theorems which we'll be formalising. There are in fact two; one (the "minimal case") is proved using an extension of the original Taylor--Wiles techniques, and the other is deduced from it using various more modern tricks which were developed later. This chapter (currently work in progress) will contain a detailed discussion of all the things involved in the statement of the theorem.

\section{Automorphic forms and analysis}

Modular forms were historically the first nontrivial examples of automorphic forms, but by the 1950s or so it was realised that they were special cases of a very general notion of an automorphic form, as were Dirichlet characters! Modular forms are holomorphic automorphic forms for the group $\GL_2/\Q$, and Dirichlet characters are automorphic forms for the group $\GL_1/\Q$. It's possible to make sense of the notion of an automorphic form for the group $G/k$. Here $k$ is a ``global field'' -- that is, a field which is either a finite extension of $\Q$ (a number field) or a finite finite extension of $(\Z/p\Z)(T)$ (a function field), and $G$ is a connected reductive group variety over $k$. 

The reason that the definition of a modular form involves some analysis (they are holomorphic functions) is that if you quotient out the group $\GL_2(\R)$ by its centre and the maximal compact subgroup $O_2(\R)$, you get something which can be naturally identified with the upper half plane, a symmetric space with lots of interesting differential operators associated to it (for example a Casimir operator). However if you do the same thing with $\GL_1(\R)$ then you get a one point set, which is why a Dirichlet character is just a combinatorial object; it's a group homomorphism $(\Z/N\Z)^\times\to\C^\times$ where $N$ is some positive integer. It turns out that there are many other connected reductive groups where the associated symmetric space is 0-dimensional, and in these cases the definition of an automorphic form is again combinatorial. An example would be the group variety associated to the units of a totally definite quaternion algebra over a totally real field. In this case, the analogue of $\GL_2(\R)$ would be the units $\bbH^\times$ in the Hamilton quaternions, a maximal compact subgroup would be the quaternions of norm 1 (homeomorphic to the 3-sphere $S^3$) and quotienting out $\bbH^\times$ by its centre $\R^\times$ and $S^3$ again just gives you 1 point. 

Before we talk about quaternion algebras, let's talk about central simple algebras.

\section{Central simple algebras}

Convention: in this section, fields are commutative, but algebras over a field may not be. An example
of what we are considering below would be Hamilton's quaternions $\R\oplus\R i\oplus\R j\oplus\R k$ as an algebra over $\R$.


\begin{definition}
    \label{IsCentralSimple}
    \lean{IsCentralSimple}
    \leanok
A \emph{central simple algebra} over a field $K$ is a $K$-algebra $D$ such that $K$ is the centre of $D$
and that $D$ has no nontrivial two-sided ideals.
\end{definition}

Equivalently, every surjective ring homomorphism $D\\twoheadrightarrow A$ to any non-commutative ring~$A$
is either an isomorphism, or the zero map to the zero ring. Note that this latter condition has nothing
to do with~$K$.

\begin{lemma}
    \label{MatrixRing.isCentralSimple}
    \lean{MatrixRing.isCentralSimple}
    \uses{IsCentralSimple}
    If $n\geq1$ then the $n\times n$ matrices $M_n(K)$ are a central simple alegbra over~$K$.
\end{lemma}
\begin{proof}
We prove more generally that matrices with coefficients in~$K$ and indexed by an arbitrary nonempty 
finite type are a central simple algebra over~$K$.

They are clearly an algebra over $K$, with $K$ embedded via scalar matrices as usual
(the injectivity of the map from~$K$ comes from nonemptiness of the finite index type). 
The centre clearly contains $K$; to show that it
equals~$K$, we argue as follows. Let $e(i,j)$ be the matrix with a 1 in the $i$th row and $j$th
column, and zeros everywhere else. An element $Z=(Z_{s,t})_{s,t}$ of the centre commutes with 
all matrices $e(i,j)$ for $i\not=j$ and these equations immediately imply that $Z_{i,j}=0$ if $i\not=j$
and that $Z_{i,i}=Z_{j,j}$.

It suffices to prove that any nonzero two-sided ideal~$I$ is all of $M_n(K)$. So say $0\not=M\in I$
and let's fix $(i,j)$ such that $M_{i,j}\not=0$. If now $N$ is any matrix, one easily checks
that $N=M_{i,j}^{-1}\sum_{k,l}e(k,i)\times M\times e(j,l)\in I$.

The definition also requires that the ring be non-zero, but this follows from the index type being nonempty.
\end{proof}

\begin{lemma}
    \label{IsCentralSimple.baseChange} % no Lean yet because Lean didn't seem to know L \otimes_K D was a ring
    If $D$ is a central simple algebra over~$K$ and $L/K$ is a field extension, then $L\otimes_KD$ 
    is a central simple algebra over~$L$.
\end{lemma}
\begin{proof}
    This is not too hard: it's lemma b of section 12.4 in Peirce's "Associative algebras".
    Will maybe write more on Saturday.
\end{proof}


Next: define trace and norm.


%\begin{lemma}
%    \label{IsQuaternionAlgebra.exists_quaternionAlgebra_iso}
%    \lean{IsQuaternionAlgebra.exists_quaternionAlgebra_iso}
%  Any such quaternion algebra has a basis $1,i,j,k$ with $i^2=a$, $j^2=b$ and $ij=-ji=k$.
%\end{lemma}
%\begin{proof}
%  Choose $d\in D\backslash K$. Then 
%\end{proof}

